{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is notebook  with autoencoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aishw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aishw\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1= Input(shape=(5500,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = Dense(encoding_dim, activation='relu')(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = Dense(5500, activation='sigmoid')(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input1, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input1, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(encoding_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layer = autoencoder.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder Model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096, 5500)\n",
      "(100, 5500)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_v2_1096.csv\", encoding=\"utf8\")\n",
    "docs = []\n",
    "#iterate over every row of the dataframe\n",
    "for index,row in df.iterrows():\n",
    "  docs.append(row[\"sent_text\"])\n",
    "\n",
    "fn = 'glove.6B.50d.txt'\n",
    "f = open(fn, encoding=\"utf8\")\n",
    "embeddings_index = dict()\n",
    "for line in f:\n",
    "  values = line.split()\n",
    "  word = values[0]\n",
    "  coefs = np.asarray(values[1:], dtype='float32')\n",
    "  embeddings_index[word] = coefs\n",
    "\n",
    "x_train = np.zeros((index+1,5500));\n",
    "sntidx = 0\n",
    "for sent in docs:\n",
    "  tok = nltk.word_tokenize(sent.lower())\n",
    "  asent = np.zeros((110,50))\n",
    "  wrds = 0\n",
    "  for token in tok:\n",
    "    if token in embeddings_index:\n",
    "      asent[wrds] = embeddings_index[token]\n",
    "      wrds += 1\n",
    "      if wrds == 110:\n",
    "        break\n",
    "  #print asent\n",
    "  x_train[sntidx] = asent.flatten()\n",
    "  sntidx += 1\n",
    "x_test = x_train[100:200]\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1096 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "1096/1096 [==============================] - 1s 1ms/step - loss: 0.6929 - val_loss: 0.6927\n",
      "Epoch 2/50\n",
      "1096/1096 [==============================] - 1s 603us/step - loss: 0.6925 - val_loss: 0.6921\n",
      "Epoch 3/50\n",
      "1096/1096 [==============================] - 1s 638us/step - loss: 0.6918 - val_loss: 0.6909\n",
      "Epoch 4/50\n",
      "1096/1096 [==============================] - 1s 906us/step - loss: 0.6903 - val_loss: 0.6885\n",
      "Epoch 5/50\n",
      "1096/1096 [==============================] - 1s 633us/step - loss: 0.6872 - val_loss: 0.6830\n",
      "Epoch 6/50\n",
      "1096/1096 [==============================] - 1s 650us/step - loss: 0.6803 - val_loss: 0.6711\n",
      "Epoch 7/50\n",
      "1096/1096 [==============================] - 1s 668us/step - loss: 0.6653 - val_loss: 0.6460\n",
      "Epoch 8/50\n",
      "1096/1096 [==============================] - 1s 726us/step - loss: 0.6347 - val_loss: 0.5966\n",
      "Epoch 9/50\n",
      "1096/1096 [==============================] - 1s 678us/step - loss: 0.5771 - val_loss: 0.5122\n",
      "Epoch 10/50\n",
      "1096/1096 [==============================] - 1s 677us/step - loss: 0.4836 - val_loss: 0.3900\n",
      "Epoch 11/50\n",
      "1096/1096 [==============================] - 1s 666us/step - loss: 0.3566 - val_loss: 0.2431\n",
      "Epoch 12/50\n",
      "1096/1096 [==============================] - 1s 619us/step - loss: 0.2137 - val_loss: 0.0994\n",
      "Epoch 13/50\n",
      "1096/1096 [==============================] - 1s 642us/step - loss: 0.0796 - val_loss: -0.0269\n",
      "Epoch 14/50\n",
      "1096/1096 [==============================] - 1s 679us/step - loss: -0.0366 - val_loss: -0.1304\n",
      "Epoch 15/50\n",
      "1096/1096 [==============================] - 1s 813us/step - loss: -0.1265 - val_loss: -0.1994\n",
      "Epoch 16/50\n",
      "1096/1096 [==============================] - 1s 840us/step - loss: -0.1851 - val_loss: -0.2435\n",
      "Epoch 17/50\n",
      "1096/1096 [==============================] - 1s 687us/step - loss: -0.2239 - val_loss: -0.2769\n",
      "Epoch 18/50\n",
      "1096/1096 [==============================] - 1s 640us/step - loss: -0.2541 - val_loss: -0.3056\n",
      "Epoch 19/50\n",
      "1096/1096 [==============================] - 1s 645us/step - loss: -0.2799 - val_loss: -0.3305\n",
      "Epoch 20/50\n",
      "1096/1096 [==============================] - 1s 657us/step - loss: -0.3025 - val_loss: -0.3517\n",
      "Epoch 21/50\n",
      "1096/1096 [==============================] - 1s 597us/step - loss: -0.3219 - val_loss: -0.3697\n",
      "Epoch 22/50\n",
      "1096/1096 [==============================] - 1s 653us/step - loss: -0.3385 - val_loss: -0.3854\n",
      "Epoch 23/50\n",
      "1096/1096 [==============================] - 1s 669us/step - loss: -0.3530 - val_loss: -0.3986\n",
      "Epoch 24/50\n",
      "1096/1096 [==============================] - 1s 922us/step - loss: -0.3652 - val_loss: -0.4097\n",
      "Epoch 25/50\n",
      "1096/1096 [==============================] - 1s 622us/step - loss: -0.3754 - val_loss: -0.4189\n",
      "Epoch 26/50\n",
      "1096/1096 [==============================] - 1s 660us/step - loss: -0.3840 - val_loss: -0.4267\n",
      "Epoch 27/50\n",
      "1096/1096 [==============================] - 1s 652us/step - loss: -0.3913 - val_loss: -0.4331\n",
      "Epoch 28/50\n",
      "1096/1096 [==============================] - 1s 697us/step - loss: -0.3972 - val_loss: -0.4387\n",
      "Epoch 29/50\n",
      "1096/1096 [==============================] - 1s 1ms/step - loss: -0.4023 - val_loss: -0.4431\n",
      "Epoch 30/50\n",
      "1096/1096 [==============================] - 1s 843us/step - loss: -0.4066 - val_loss: -0.4468\n",
      "Epoch 31/50\n",
      "1096/1096 [==============================] - 1s 660us/step - loss: -0.4102 - val_loss: -0.4502\n",
      "Epoch 32/50\n",
      "1096/1096 [==============================] - 1s 675us/step - loss: -0.4135 - val_loss: -0.4530\n",
      "Epoch 33/50\n",
      "1096/1096 [==============================] - 1s 648us/step - loss: -0.4163 - val_loss: -0.4554\n",
      "Epoch 34/50\n",
      "1096/1096 [==============================] - 1s 658us/step - loss: -0.4187 - val_loss: -0.4577\n",
      "Epoch 35/50\n",
      "1096/1096 [==============================] - 1s 645us/step - loss: -0.4209 - val_loss: -0.4594\n",
      "Epoch 36/50\n",
      "1096/1096 [==============================] - 1s 623us/step - loss: -0.4227 - val_loss: -0.4612\n",
      "Epoch 37/50\n",
      "1096/1096 [==============================] - 1s 596us/step - loss: -0.4244 - val_loss: -0.4626\n",
      "Epoch 38/50\n",
      "1096/1096 [==============================] - 1s 619us/step - loss: -0.4258 - val_loss: -0.4638\n",
      "Epoch 39/50\n",
      "1096/1096 [==============================] - 1s 594us/step - loss: -0.4272 - val_loss: -0.4650\n",
      "Epoch 40/50\n",
      "1096/1096 [==============================] - 1s 617us/step - loss: -0.4283 - val_loss: -0.4661\n",
      "Epoch 41/50\n",
      "1096/1096 [==============================] - 1s 631us/step - loss: -0.4295 - val_loss: -0.4671\n",
      "Epoch 42/50\n",
      "1096/1096 [==============================] - 1s 620us/step - loss: -0.4304 - val_loss: -0.4679\n",
      "Epoch 43/50\n",
      "1096/1096 [==============================] - 1s 612us/step - loss: -0.4313 - val_loss: -0.4687\n",
      "Epoch 44/50\n",
      "1096/1096 [==============================] - 1s 876us/step - loss: -0.4321 - val_loss: -0.4691\n",
      "Epoch 45/50\n",
      "1096/1096 [==============================] - 1s 1ms/step - loss: -0.4328 - val_loss: -0.4697\n",
      "Epoch 46/50\n",
      "1096/1096 [==============================] - 1s 789us/step - loss: -0.4335 - val_loss: -0.4704\n",
      "Epoch 47/50\n",
      "1096/1096 [==============================] - 1s 792us/step - loss: -0.4341 - val_loss: -0.4710\n",
      "Epoch 48/50\n",
      "1096/1096 [==============================] - 1s 955us/step - loss: -0.4347 - val_loss: -0.4713\n",
      "Epoch 49/50\n",
      "1096/1096 [==============================] - 1s 735us/step - loss: -0.4352 - val_loss: -0.4717\n",
      "Epoch 50/50\n",
      "1096/1096 [==============================] - 1s 682us/step - loss: -0.4356 - val_loss: -0.4722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2181a388710>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encoder.predict(x_test)\n",
    "decoded = decoder.predict(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 6 # how many digits we will display\n",
    "plt.figure(figsize=(2, 2))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(110,50))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(110, 50))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
