{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Deep Leraning for NLP****\n",
    "Topic : Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aishw\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['bad',\n",
    "        'badly',\n",
    "        'terrible',\n",
    "        'good',\n",
    "        'great',\n",
    "       'awesome']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1574], [2644], [3861], [4904], [4390], [3440]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define class labels\n",
    "labels = array([0,0,0,1,1,1])\n",
    "# integer encode the documents\n",
    "vocab_size = 6000\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1574    0    0 ...    0    0    0]\n",
      " [2644    0    0 ...    0    0    0]\n",
      " [3861    0    0 ...    0    0    0]\n",
      " [4904    0    0 ...    0    0    0]\n",
      " [4390    0    0 ...    0    0    0]\n",
      " [3440    0    0 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "max_length = 350\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 350, 8)            48000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2800)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2801      \n",
      "=================================================================\n",
      "Total params: 50,801\n",
      "Trainable params: 50,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 50.000000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=5, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 8)\n",
      "[[1574], [2644], [3861], [4904], [4390], [3440]]\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 6000 samples in 0.011s...\n",
      "[t-SNE] Computed neighbors for 6000 samples in 7.193s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 6000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 6000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 6000\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 6000\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 6000\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 6000\n",
      "[t-SNE] Mean sigma: 0.022261\n",
      "[t-SNE] KL divergence after 50 iterations with early exaggeration: 92.440941\n"
     ]
    }
   ],
   "source": [
    "embds = model.layers[0].get_weights()[0]\n",
    "print(embds.shape)\n",
    "word_list = encoded_docs\n",
    "print(word_list)\n",
    "\n",
    "def plot_embedding(data, start, stop, step, fname):\n",
    "  words = word_list[start:stop:step]\n",
    "  x = data[start:stop:step,0]\n",
    "  y = data[start:stop:step, 1]\n",
    "  cm = plt.cm.get_cmap('RdYlGn')\n",
    "  f = plt.figure(figsize=(8, 6))\n",
    "  ax = plt.subplot(aspect='equal')\n",
    "  sc = ax.scatter(x, y, lw=0, s=100, cmap=cm, alpha=1.0, marker='.', edgecolor='')\n",
    "  plt.xlim(-25, 25)\n",
    "  plt.ylim(-25, 25)\n",
    "  ax.set_title('TSNE of Word Embeddings')\n",
    "  ax.set_xlabel('TSNE 1st Dimension')\n",
    "  ax.set_ylabel('TSNE 2nd Dimension')\n",
    "  ax.axis('tight')\n",
    "\n",
    "  plt.savefig(fname + '.png')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "tsne_embds = TSNE(n_components=2, verbose=1).fit_transform(embds)\n",
    "plot_embedding(tsne_embds, 0, len(word_list), 1, \"tsne_embds\")\n",
    "\n",
    "#\n",
    "#conv_tsne_embds = TSNE(n_components=2).fit_transform(conv_embds)\n",
    "#plot_embedding(conv_tsne_embds, 0, len(word_list), 1, \"conv_tsne_embds\")\n",
    "#\n",
    "#glove_tsne_embds = TSNE(n_components=2).fit_transform(glove_emds)\n",
    "#plot_embedding(glove_tsne_embds, 0, len(word_list), 1, \"glove_tsne_embds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
